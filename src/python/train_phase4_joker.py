"""
OFC Pineapple AI - Phase 4-1 Training (Joker Edition)
ã‚¸ãƒ§ãƒ¼ã‚«ãƒ¼ã‚’å«ã‚€54ã‚«ãƒ¼ãƒ‰ç’°å¢ƒã§ã®Phase 1ãƒ•ã‚¡ã‚¦ãƒ«å›é¿å­¦ç¿’

ç‰¹å¾´:
- 54ã‚«ãƒ¼ãƒ‰ç’°å¢ƒï¼ˆJoker 2æšã‚’å«ã‚€ï¼‰
- ã‚¸ãƒ§ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¦ãƒ«ç‡ãŒ52æšç‰ˆã‚ˆã‚Šæ—©ãä½ä¸‹ã™ã‚‹è¦‹è¾¼ã¿
"""

import os
import argparse
from datetime import datetime
from sb3_contrib import MaskablePPO
from stable_baselines3.common.callbacks import CheckpointCallback, BaseCallback

from src.python.ofc_phase1_env import OFCPhase1Env

class Phase4Callback(BaseCallback):
    """
    ã‚¸ãƒ§ãƒ¼ã‚«ãƒ¼å¯¾å¿œå­¦ç¿’ã®é€²æ—ã‚’è¨˜éŒ²ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    def __init__(self, verbose=0):
        super().__init__(verbose)
        self.game_results = []
        self.log_file = None
        
    def _on_training_start(self):
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        os.makedirs("logs/phase4", exist_ok=True)
        self.log_file = open(f"logs/phase4/phase4_log_{timestamp}.txt", "w")
        self.log_file.write("step,games,foul_rate,mean_royalty\n")
        
    def _on_step(self) -> bool:
        # infoã‹ã‚‰ã‚²ãƒ¼ãƒ çµæœã‚’å–å¾—
        for info in self.locals.get("infos", []):
            if "fouled" in info:
                self.game_results.append({
                    "fouled": info["fouled"],
                    "royalty": info.get("royalty", 0)
                })
        
        # å®šæœŸçš„ãªå‡ºåŠ›ï¼ˆ5000ã‚¹ãƒ†ãƒƒãƒ—æ¯ï¼‰
        if self.n_calls % 5000 == 0 and self.game_results:
            recent = self.game_results[-100:]
            foul_rate = sum(1 for r in recent if r["fouled"]) / len(recent)
            mean_royalty = sum(r["royalty"] for r in recent) / len(recent)
            
            print(f"\n[Step {self.num_timesteps}] ğŸƒ Phase 4-1 (Joker)")
            print(f"  Games: {len(self.game_results)}")
            print(f"  Foul Rate (last 100): {foul_rate:.1%}")
            print(f"  Mean Royalty (last 100): {mean_royalty:.1f}")
            print("-" * 40)
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
            if self.log_file:
                self.log_file.write(f"{self.num_timesteps},{len(self.game_results)},{foul_rate:.4f},{mean_royalty:.1f}\n")
                self.log_file.flush()
            
        return True
    
    def _on_training_end(self):
        if self.log_file:
            self.log_file.close()

def train():
    parser = argparse.ArgumentParser()
    parser.add_argument("--timesteps", type=int, default=500000,
                        help="å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 500000ï¼‰")
    parser.add_argument("--lr", type=float, default=3e-4,
                        help="å­¦ç¿’ç‡")
    parser.add_argument("--batch-size", type=int, default=128,
                        help="ãƒãƒƒãƒã‚µã‚¤ã‚º")
    parser.add_argument("--save-name", type=str, default=None,
                        help="ãƒ¢ãƒ‡ãƒ«ä¿å­˜å")
    args = parser.parse_args()
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜å
    if args.save_name is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.save_name = f"ofc_phase4_joker_{timestamp}"
    
    # ç’°å¢ƒä½œæˆï¼ˆPhase 4: 54ã‚«ãƒ¼ãƒ‰ç’°å¢ƒï¼‰
    print("=" * 60)
    print("ğŸƒ OFC Pineapple AI - Phase 4-1 Training (Joker Edition)")
    print("=" * 60)
    print(f"  Environment: 54 cards (52 + 2 Jokers)")
    print(f"  Timesteps: {args.timesteps:,}")
    print(f"  Learning Rate: {args.lr}")
    print(f"  Batch Size: {args.batch_size}")
    print("=" * 60)
    
    env = OFCPhase1Env(reward_royalties=False)  # Phase 1: ãƒ•ã‚¡ã‚¦ãƒ«å›é¿ãƒ•ã‚©ãƒ¼ã‚«ã‚¹
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ç”¨
    os.makedirs("models/phase4", exist_ok=True)
    checkpoint_callback = CheckpointCallback(
        save_freq=50000,
        save_path="./models/phase4/",
        name_prefix=args.save_name
    )
    
    phase4_callback = Phase4Callback()
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ (MaskablePPO)
    model = MaskablePPO(
        "MultiInputPolicy",
        env,
        learning_rate=args.lr,
        n_steps=2048,
        batch_size=args.batch_size,
        n_epochs=10,
        gamma=0.99,
        verbose=1,
        tensorboard_log="./logs/phase4/"
    )
    
    print("\nğŸš€ Starting training...")
    
    # å­¦ç¿’é–‹å§‹
    model.learn(
        total_timesteps=args.timesteps,
        callback=[checkpoint_callback, phase4_callback]
    )
    
    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model.save(f"models/phase4/{args.save_name}_final")
    print(f"\nâœ… Model saved to models/phase4/{args.save_name}_final")

if __name__ == "__main__":
    train()
