# 1億ステップを超えて：OFC Pineapple AI Phase 8.5完了レポート

*2026年1月24日*

---

## はじめに

オープンフェイスチャイニーズポーカー（OFC）パイナップル3人戦のAI開発プロジェクト、Phase 8.5が完了しました。

今回は**1億ステップ（約1,024万ゲーム）**という過去最大規模の学習を実施。Ultimate Rulesに対応したFantasy Land（FL）システムを完全実装し、AIの戦略能力を大幅に向上させました。

---

## Phase 8.5の目標

Phase 8.5では以下を目標としました：

1. **Ultimate Rules FL対応** - FL突入時の配布枚数をハンド強度に応じて変化
2. **FL状態の継続学習** - ゲーム間でFL状態を引き継ぐ連続ゲームモード
3. **大規模学習による性能向上** - 100Mステップで戦略を洗練

### Ultimate Rules Fantasy Land

通常のOFCでは、Fantasy Landに突入すると14枚のカードが配られます。しかしUltimate Rulesでは、トップハンドの強さに応じて配布枚数が変化します：

| トップハンド | 配布枚数 | 難易度 |
|:------------|:--------:|:------:|
| QQ | 14枚 | 標準 |
| KK | 15枚 | やや易 |
| AA | 16枚 | 易 |
| Trips | 17枚 | 最易 |

枚数が多いほど、より強いハンドを作りやすくなります。

---

## 学習結果

### 最終メトリクス

```
═══════════════════════════════════════
Phase 8.5 Final Results (100M Steps)
═══════════════════════════════════════
ゲーム数:     10,240,000
ファウル率:   22.0%
平均スコア:   +8.43
平均ロイヤリティ: 1.40
FL突入率:     8.2%
勝率:        68.8%
学習時間:     約22.5時間
═══════════════════════════════════════
```

### Phase 8との比較

![Phase Comparison](../plots/phase85/phase_comparison.png)

| 指標 | Phase 8 | Phase 8.5 | 変化 |
|:-----|:-------:|:---------:|:----:|
| ファウル率 | **20.8%** | 22.0% | +1.2% |
| 平均スコア | +7.87 | **+8.43** | +0.56 |
| FL突入率 | 3.2% | **8.2%** | **+156%** |
| ロイヤリティ | 0.87 | **1.40** | +0.53 |

---

## 学習曲線の分析

![Training Curves](../plots/phase85/training_curves.png)

### 注目ポイント

1. **FL突入率の向上**
   - 学習初期の3-4%から、最終的に8.2%まで上昇
   - AIがFL狙いの価値を理解している証拠

2. **ファウル率とのトレードオフ**
   - Phase 8の20.8%から22.0%に若干上昇
   - FL重視の積極的な戦略の副作用
   - しかしスコア期待値は大幅に向上

3. **勝率の安定**
   - Self-Play Pool相手に68.8%の勝率
   - 過去の自分自身より強くなり続ける

---

## 技術的なチャレンジ

### 連続ゲームモードの実装

FL状態を次ゲームに引き継ぐには、ゲーム終了後も環境をリセットしない「連続ゲームモード」が必要でした。

```python
continuous_games=True  # FL状態がゲーム間で保持される
```

### 終了エージェント問題の解決

PettingZoo環境では、ゲーム終了したエージェントへのアクション送信でエラーが発生。状態整合性チェックで解決しました。

### 無限ループの防止

相手プレイヤーの自動プレイ中に無限ループが発生する問題を、イテレーション上限で対策。

---

## 純粋なRLの限界

### Explained Varianceの壁

今回の学習でも、Explained Variance（状態価値予測の精度）は0.247と低い値に留まりました。理想的には0.8以上が望ましいですが、OFCは運の要素が大きく、純粋なニューラルネットワークでの予測には限界があります。

### 次のステップ：Hybrid Agent

この限界を超えるため、次フェーズでは**Hybrid Agent**（RL + Solver）を構築します：

- **ラウンド1-3**: RLポリシーで大局的な判断
- **ラウンド4-5**: ソルバーで確定的なリスク回避
- **目標**: ファウル率15%以下

---

## まとめ

Phase 8.5では、1億ステップの大規模学習を通じて：

- **FL突入率8.2%** を達成（+156%向上）
- **平均スコア+8.43** で過去最高
- **勝率68.8%** で安定した強さを実現

純粋な強化学習としては優れた結果ですが、実用レベルのAIには更なる改良が必要です。現在、FL専門モデル（FL Specialist）の学習を並行して実施中です。

次回は、Hybrid Agentの実装と、実際の人間との対戦テスト結果をお届けする予定です。

---

## 参考資料

- [Phase 8.5 詳細レポート](../research/phase85_training_report.md)
- [学習曲線グラフ](../plots/phase85/)
- [GitHub リポジトリ](https://github.com/naoai/ofc-nn)

---

*OFC Pineapple AI Project - Phase 8.5 Completion Report*
